# 集群的运维和稳定性

- 检查节点健康 etcdctl endpoint health
- 备份数据 etcdctl snapshot save backup.db

## 运行时重配置

两阶段配置更新保证集群安全。
- 阶段1：广播通知集群，新的配置
- 阶段2：启动新集群

## 永久失去半数以上的member

- 不建议通过移除节点的方式进行恢复，因为她绕过了raft一致性，不安全。
- 出现丢失半数节点的概率非常低，但也要考虑到
- 服务发现适用于etcd集群部署之初，不适合运行时重配置
- 丢半数节点的正确解决方式：基于旧数据，启动一个新集群

## 参数调优

主要是调整etcd心跳间隔和选举超时时间，这些都受延时影响，
延时来源：
- 网络延时
- 磁盘io会导致延时

心跳间隔，默认是100ms，选举超时时间默认是1000ms，最大值是50s。
- 心跳间隔推荐使用rtt最大值，一般设置成0.5-1.5倍rtt值即可
- 选举超时时间推荐10倍rtt值

```shell
    etcd --heartbeat-interval=100 --election-timeout=500
    ETCD_HEARTBEAT_INTERVAL=100 ETD_ELECTION_TIMEOUT=500
```

除时间外，创建快照也很影响内存和磁盘使用
```shell
    etcd --snapshot=count=5000   # v2默认是10000条日志创建一次快照，压力大就应该降低触发阀值
    ETCD_SNAPSHOT_COUNT=5000
```

etcd对磁盘i/o很敏感，应该赋予etcd更高的磁盘i/o权限。
```shell
    sudo ionice -c2 -n0 -p 'pgrep etcd'
````

etcd对网络i/o也有很大的需求，权限提升如下：
```shell
    tc qdisc add dev eth0 root handle 1:prio bands 3
```

## 监控

通过 curl -L http://localhost:2379/metrics 即可查看监控数据

## 维护

维护都会严重影响etcd性能，但不维护会导致不可用，只能定期做维护。
这维护更多的是操作etcd的存储空间。

- 压缩key的历史版本
  - 启动参数 --auto-compaction 支持自动压缩
  - --auto-compaction-retention=1 保留1小时的历史版本
  - etcdctl compact 3 压缩至版本号3
- 清理压缩后的碎片
  - etcdctl defrag
- 存储配额，报警之后只接受读和删除
  - etcd --quota-backend-bytes=$(16*1024*1024)  16M
  - 报警之后的操作是：获取当前版本号、压缩、清理碎片、消除警告、测试写操作
- 快照备份，方便恢复时有一个良好的状态
  - 备份 etcdctl snapshot save backup.db
  - 查询 etcdctl --write-out=table snapshot status backup.db

## 灾难恢复

容灾能力，也就是自动故障恢复

故障恢复有以下步骤：
- 保存当前活动节点的快照
  - etcdctl --endpoints $ENDPOINT snapshot save snapshot.db
- 恢复集群
  - etctctl snapshot restore 

## etcd 网关

网关就是一个tcp代理，用于向集群转发网络数据。
网关后面可以支持多个etcd服务器，支持轮询方式的负载均衡策略。

什么时候用etcd网关：  
    应用程序直接访问etcd节点，具体的etcd服务的ip地址可能在运行时变化，
对此，每个节点运行一个etcd网关，那么etcd服务对应用程序来说是透明的。

什么时候不适合用etcd网关：  
- 高性能场景不适合用etcd网关，因为网关没有缓存、watch合并、批处理机制
- 已有服务发现机制，就不需要用太原始的方式了

## grpc代理

grpc是在osi7层模型中的会话层、一个无状态的反向代理。

这个代理是为了降低集群的请求负载。

过程是，随机选中一个etcd服务，将所有的请求转给该服务，直到该服务故障，
会切到另一个etcd服务上。

grpc代理还合并了watch api和lease api，缓冲了范围查的结果。
 
- 将同一个key或同一个范围上，多个客户端的watch请求合并成一个。典型是为了提高性能而设计的
- 合并watch 代理的副作用是 响应版本不那么精确
- 租约心跳合并，也是为了提高etcd服务器性能而设计的
- 缓存部分响应，减少etcd服务器负担
- 代理支持后端节点的服务发现
- 通过namespace进行资源隔离：一个集群对多个应用提供服务，相互之间是数据隔离的

grpc代理，直接用etcd的代理模式启动即可，使用etcd代理和etcd集群，可大大提高性能。

## 故障恢复

上面也提到了定期备份etcd数据，可避免不可恢复错误。下面将具体故障分类：

- 小部分群众节点故障
  - 集群对外功能不受影响
  - 客户端如果连接着故障节点，那么连接会断开
- 领袖节点故障
  - 集群会经过领袖心跳超时、选举
  - 这个过程中，集群不会处理写操作，写操作都会被缓存到队列
  - 这个过程中，旧领袖节点上如果还有写没有提交，那么这个数据会丢失
  - 用户角度，就是写超时了，重试即可，业务上不会有问题
- 大部分节点故障
  - 集群只能等大部分节点可用时才会对外提供功能
  - 如果是永久性故障，那么就参考上面的灾难恢复手段
- 网络分区
  - 那会存在两部分网络："大部分节点的网络" 和 "小部分节点的网络"
  - 大部分节点的网络 正常对外提供功能； 小部分的不提供功能
  - 所以etcd 网络分区，不会造成脑裂情况
- 集群启动异常
  - 只有集群所有节点启动ok，集群才算是启动成功

## 硬件

最低有效运行要求：
- cpu：etcd需要大量cpu资源，2-4核能保证系统运行，高负载需要8-16核，用以支持万每秒的请求。
- 内存：8G满足一般场景，上百万key、上千watch，需要16-64G
- 磁盘：etcd性能和稳定性最关键的因素。7200转满足一般场景，高负责需要ssd。推荐使用ssd或15000转
- 网络：好的网络条件对多成员的集群有帮助，千兆网络满足一般场景，大集群使用万兆网络 10GBE

硬件配置示例：

    小型集群：  客户端<10   请求数<200/s   存储的数据不超过100MB  50个k8s成员   2核/8G/3600并行iops/50MB/s的磁盘带宽
    中型集群：  客户端<500  请求数<1000/s  存储的数据不超过500MB  250个k8s成员  4核/16G/6000并行iops/100MB/s的磁盘带宽
    大型集群：  客户端<1500 请求数<10000/s 存储的数据不超过1GB    1000个k8s成员 8核/32G/8000并行iops/125MB/s的磁盘带宽
    超大型集群：客户端>1500 请求数>10000/s 存储的数据超过1GB      3000个k8s成员 16核/64G/16000并行iops/250MB/s的磁盘带宽

硬件问题容易导致 领袖心跳问题：领袖在，群众收到的心跳超时，一般可能是以下原因：
- 磁盘i/o慢
- cpu不足
- 网络慢

应对手段要么是升级硬件，要么是权限提升。还可以运行时重配置，将心跳超时和选举超时配置大一点。




